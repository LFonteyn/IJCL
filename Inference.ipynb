{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf390852-3f3f-4d0b-822e-20b7d04bb084",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook explains how to load a fine-tuned MacBERTh model and use it for inference. It also evaluates the results of the model on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b58e11f-7d1c-4267-90ed-362fc5fa8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from finetune import read_data, encode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb2d8a-6e26-4161-8f69-9f9551c9a0e3",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "Here, we load the model from the huggingface hub. This model is a version of MacBERTh that is fine-tuned on a dataset of ing-forms to perform a 5-wise classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c6cd289-7af7-4600-af6b-284f073e979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39146e928ac14fa183e76029f7af62f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef962f0fd3d3403187dc54e56e2394f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73080169c78f4ccc98afc7a3505e1118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063e1967bca7435ba231f458e99161d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b2ef321f024ce1b6ce5223cc6ad89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ca6348be449e8ae3fd38c6aa5c1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b500271915ab4ea6a833196497d19748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = AutoModelForSequenceClassification.from_pretrained('emanjavacas/MacBERTh-ing')\n",
    "tokenizer = AutoTokenizer.from_pretrained('emanjavacas/MacBERTh-ing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906573c1-8984-4f67-ada7-24d50b0b8e7f",
   "metadata": {},
   "source": [
    "Given an input sentence such as the following, we can use the model for classification as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7607b8b9-bc50-411f-ae38-2c06ed9fd881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Church about half a mile from her house, being about twenty weeks gone with Child, and to her thinking very well and healthy, upon a sudden she was taken with great pains and miscarried before she came'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Church about half a mile from her house, being about twenty weeks gone ' + \\\n",
    "'with Child, and to her thinking very well and healthy, upon a sudden she was taken ' + \\\n",
    "'with great pains and miscarried before she came'\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e835688c-ee7e-4337-87c3-16441e700dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.9836,  7.5749, -1.4609, -2.8214, -2.4386]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tokenizer(sentence, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83173dcf-a544-4fd6-97b3-5f351ae64832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOMINAL-ING'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.argmax(output.logits.numpy())\n",
    "m.config.id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36045f-ffce-4473-b47a-25fb4abd4b47",
   "metadata": {},
   "source": [
    "## Adding the markers\n",
    "\n",
    "However, since more than one ing-form may occur in the sentence, we fine-tuned the model adding markers to lead the model's attention towards the token that we want predictions for. \n",
    "\n",
    "It is important that we do this also during training, since it will have a big impact on the model's performance. The following example illustrates the divergent behaviour.\n",
    "\n",
    "The markers are the `'[TGT]'` symbols before and after the target token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb8db42a-9585-4a39-b4ec-e4a51ff44b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_raw = \"Every Gay thing to be a Cavalier; Every Parish - Clerk to be a Doctor; \" + \\\n",
    "\"and Every writing Clerk in the Office must be call'd Mr Secretary. So that the whole \" + \\\n",
    "\"world, take it where you will\"\n",
    "\n",
    "data = tokenizer(sentence_raw, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "prediction = np.argmax(output.logits.numpy())\n",
    "m.config.id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a8908b0-bcd6-437f-a677-562c6eeedbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PARTICIPLE'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_marked = \"Every Gay thing to be a Cavalier; Every Parish - Clerk to be a Doctor; \" + \\\n",
    "\"and Every [TGT] writing [TGT] Clerk in the Office must be call'd Mr Secretary. So that the whole \" + \\\n",
    "\"world, take it where you will\"\n",
    "\n",
    "data = tokenizer(sentence_marked, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "prediction = np.argmax(output.logits.numpy())\n",
    "m.config.id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f98d2-7a6b-44c4-9bbb-0ca030d7f3f5",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "Here we load a dataset that has sentences in the format as we used them during fine-tuning. We will use these sentences and the associated labels to perform an evaluation of the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2e20c8-e317-42d3-910b-8fc846de7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test_set_ing.EMMA.merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3159617b-42de-41ce-990e-90780818111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>docid</th>\n",
       "      <th>genre</th>\n",
       "      <th>lhs</th>\n",
       "      <th>match</th>\n",
       "      <th>rhs</th>\n",
       "      <th>level-1</th>\n",
       "      <th>level-2</th>\n",
       "      <th>level-3</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>lhs-clean</th>\n",
       "      <th>rhs-clean</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>617966</td>\n",
       "      <td>Burnet, Gilbert</td>\n",
       "      <td>1681</td>\n",
       "      <td>10624521</td>\n",
       "      <td>prose</td>\n",
       "      <td>that which remained of the Episcopal Dignity ,...</td>\n",
       "      <td>recovering</td>\n",
       "      <td>that which was lost . This was signified to Ca...</td>\n",
       "      <td>NOMINAL-ING</td>\n",
       "      <td>NO-OBJ-GERUND</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The history of the rights of princes in the di...</td>\n",
       "      <td>that which remained of the Episcopal Dignity ,...</td>\n",
       "      <td>that which was lost . This was signified to Ca...</td>\n",
       "      <td>recovering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index           author  year     docid  genre  \\\n",
       "0  617966  Burnet, Gilbert  1681  10624521  prose   \n",
       "\n",
       "                                                 lhs       match  \\\n",
       "0  that which remained of the Episcopal Dignity ,...  recovering   \n",
       "\n",
       "                                                 rhs      level-1  \\\n",
       "0  that which was lost . This was signified to Ca...  NOMINAL-ING   \n",
       "\n",
       "         level-2 level-3  comment  \\\n",
       "0  NO-OBJ-GERUND       G      NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0  The history of the rights of princes in the di...   \n",
       "\n",
       "                                           lhs-clean  \\\n",
       "0  that which remained of the Episcopal Dignity ,...   \n",
       "\n",
       "                                           rhs-clean         ing  \n",
       "0  that which was lost . This was signified to Ca...  recovering  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13d02cf7-f69f-4717-905d-ae0e6a0e040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(example):\n",
    "    return ' '.join(example.split())\n",
    "\n",
    "lhs, target, rhs = 'lhs', 'match', 'rhs'\n",
    "for heading in [lhs, target, rhs]:\n",
    "    # replace NaNs with empty space\n",
    "    test[heading] = test[heading].fillna('')\n",
    "    # normalise whitespaces\n",
    "    test[heading] = test[heading].transform(normalise)\n",
    "    \n",
    "# pull sentences together\n",
    "sents, starts, ends = read_data(test[lhs], test[target], test[rhs], sym='[TGT]')\n",
    "# transform into model input format\n",
    "sents, spans = encode_data(tokenizer, sents, starts, ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b022d-c181-484a-ab02-1c869f4197f3",
   "metadata": {},
   "source": [
    "# Gather predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdf9f9e5-7596-4098-ac24-82d053b2a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|████▎                                                                                                                                                                   | 1/39 [00:06<04:20,  6.85s/it]\u001b[A\n",
      "  5%|████████▌                                                                                                                                                               | 2/39 [00:14<04:29,  7.28s/it]\u001b[A\n",
      "  8%|████████████▉                                                                                                                                                           | 3/39 [00:20<04:07,  6.87s/it]\u001b[A\n",
      " 10%|█████████████████▏                                                                                                                                                      | 4/39 [00:27<03:54,  6.69s/it]\u001b[A\n",
      " 13%|█████████████████████▌                                                                                                                                                  | 5/39 [00:34<03:51,  6.81s/it]\u001b[A\n",
      " 15%|█████████████████████████▊                                                                                                                                              | 6/39 [00:40<03:40,  6.69s/it]\u001b[A\n",
      " 18%|██████████████████████████████▏                                                                                                                                         | 7/39 [00:47<03:35,  6.72s/it]\u001b[A\n",
      " 21%|██████████████████████████████████▍                                                                                                                                     | 8/39 [00:53<03:23,  6.57s/it]\u001b[A\n",
      " 23%|██████████████████████████████████████▊                                                                                                                                 | 9/39 [01:02<03:35,  7.18s/it]\u001b[A\n",
      " 26%|██████████████████████████████████████████▊                                                                                                                            | 10/39 [01:09<03:28,  7.20s/it]\u001b[A\n",
      " 28%|███████████████████████████████████████████████                                                                                                                        | 11/39 [01:16<03:16,  7.02s/it]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▍                                                                                                                   | 12/39 [01:22<03:07,  6.94s/it]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 13/39 [01:28<02:52,  6.63s/it]\u001b[A\n",
      " 36%|███████████████████████████████████████████████████████████▉                                                                                                           | 14/39 [01:35<02:45,  6.63s/it]\u001b[A\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                      | 15/39 [01:42<02:42,  6.77s/it]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▌                                                                                                  | 16/39 [01:49<02:35,  6.75s/it]\u001b[A\n",
      " 44%|████████████████████████████████████████████████████████████████████████▊                                                                                              | 17/39 [01:55<02:28,  6.75s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████                                                                                          | 18/39 [02:02<02:18,  6.60s/it]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 19/39 [02:09<02:14,  6.70s/it]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 20/39 [02:15<02:08,  6.74s/it]\u001b[A\n",
      " 54%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 21/39 [02:22<02:00,  6.67s/it]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 22/39 [02:28<01:52,  6.60s/it]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 23/39 [02:35<01:47,  6.72s/it]\u001b[A\n",
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 24/39 [02:42<01:38,  6.56s/it]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                                            | 25/39 [02:48<01:30,  6.48s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 26/39 [02:55<01:28,  6.79s/it]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 27/39 [03:02<01:21,  6.75s/it]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 28/39 [03:09<01:13,  6.67s/it]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 29/39 [03:15<01:04,  6.49s/it]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 30/39 [03:21<00:56,  6.33s/it]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                  | 31/39 [03:27<00:51,  6.46s/it]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 32/39 [03:34<00:45,  6.48s/it]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 33/39 [03:40<00:38,  6.37s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 34/39 [03:47<00:32,  6.51s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 35/39 [03:53<00:26,  6.55s/it]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 36/39 [04:00<00:19,  6.46s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 37/39 [04:06<00:12,  6.44s/it]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 38/39 [04:12<00:06,  6.38s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [04:19<00:00,  6.46s/it]\u001b[A\n",
      "40it [04:22,  6.56s/it]                                                                                                                                                                                     \u001b[A\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "preds, probs = [], []\n",
    "n_batches = len(sents) // batch_size\n",
    "for start in tqdm.tqdm(range(0, len(sents), batch_size), total=n_batches):\n",
    "    with torch.no_grad():\n",
    "        # input batch data\n",
    "        input_data = tokenizer(sents[start:start+batch_size], return_tensors='pt', padding=True)\n",
    "        # output from the model\n",
    "        output = m(**input_data)\n",
    "        # probabilities and predictions\n",
    "        logits = output.logits.numpy()\n",
    "        probs_ = softmax(output.logits.numpy(), axis=1)\n",
    "        preds_ = np.argmax(probs_, axis=1)\n",
    "        preds_ = [m.config.id2label[id] for id in preds_]\n",
    "        preds.extend(preds_)\n",
    "        probs.extend(probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2611861-8332-4af3-bcb0-64a2e66b9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b210825-53f9-4267-b77f-db5a67110751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NAME       1.00      0.67      0.80         6\n",
      " NOMINAL-ING       0.94      0.69      0.80       657\n",
      "        NOUN       0.72      0.84      0.78       160\n",
      "  PARTICIPLE       0.76      0.91      0.83       729\n",
      "        VERB       0.60      0.89      0.72        27\n",
      "\n",
      "    accuracy                           0.81      1579\n",
      "   macro avg       0.81      0.80      0.78      1579\n",
      "weighted avg       0.83      0.81      0.81      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test['level-1'].values, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b7126-57a4-4bdd-9427-e53c9ba9582b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
